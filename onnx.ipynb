{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60744ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: onnx in /home/bizon/anaconda3/envs/ai_models/lib/python3.10/site-packages (1.13.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/bizon/anaconda3/envs/ai_models/lib/python3.10/site-packages (from onnx) (1.26.3)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.2 in /home/bizon/anaconda3/envs/ai_models/lib/python3.10/site-packages (from onnx) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /home/bizon/anaconda3/envs/ai_models/lib/python3.10/site-packages (from onnx) (4.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: onnx-simplifier in /home/bizon/.local/lib/python3.10/site-packages (0.4.8)\n",
      "Requirement already satisfied: onnx in /home/bizon/anaconda3/envs/ai_models/lib/python3.10/site-packages (from onnx-simplifier) (1.13.0)\n",
      "Requirement already satisfied: rich in /home/bizon/anaconda3/envs/ai_models/lib/python3.10/site-packages (from onnx-simplifier) (13.4.2)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/bizon/anaconda3/envs/ai_models/lib/python3.10/site-packages (from onnx->onnx-simplifier) (1.26.3)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.2 in /home/bizon/anaconda3/envs/ai_models/lib/python3.10/site-packages (from onnx->onnx-simplifier) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /home/bizon/anaconda3/envs/ai_models/lib/python3.10/site-packages (from onnx->onnx-simplifier) (4.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/bizon/anaconda3/envs/ai_models/lib/python3.10/site-packages (from rich->onnx-simplifier) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/bizon/anaconda3/envs/ai_models/lib/python3.10/site-packages (from rich->onnx-simplifier) (2.13.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/bizon/anaconda3/envs/ai_models/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->onnx-simplifier) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tensorrt in /home/bizon/anaconda3/envs/ai_models/lib/python3.10/site-packages (8.6.1.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install onnx\n",
    "%pip install onnx-simplifier # Install if you want to use simplify\n",
    "%pip install tensorrt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2418b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/bizon/projects/experiments/mmdetection_yolo/mmyolo_test/work_dirs/yolov8_l_syncbn_fast_8xb16-500e_coco/best_coco_bbox_mAP_epoch_150.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9662844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bizon/projects/experiments/mmdetection_yolo/mmyolo_test'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b09e5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export ONNX with bbox decoder and NMS ...\n",
      "Loads checkpoint by local backend from path: work_dirs/yolov8_l_planitar/best_coco_bbox_mAP_epoch_200.pth\n",
      "tensor([[[2.6420e-06, 3.4048e-06, 5.1786e-07,  ..., 1.1198e-07,\n",
      "          1.5851e-07, 3.1042e-07],\n",
      "         [1.4929e-06, 1.8949e-06, 4.7566e-07,  ..., 7.3506e-08,\n",
      "          1.0516e-07, 2.8325e-07],\n",
      "         [1.7293e-06, 2.0379e-06, 5.7483e-07,  ..., 1.0807e-07,\n",
      "          1.2615e-07, 4.2165e-07],\n",
      "         ...,\n",
      "         [1.0137e-05, 2.1717e-06, 2.1370e-06,  ..., 7.6352e-07,\n",
      "          7.0239e-07, 6.3568e-07],\n",
      "         [1.1687e-05, 2.6276e-06, 2.1325e-06,  ..., 7.6168e-07,\n",
      "          7.0075e-07, 6.3523e-07],\n",
      "         [3.1379e-06, 1.5073e-06, 1.7049e-06,  ..., 6.8885e-07,\n",
      "          6.3803e-07, 5.8625e-07]]], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward0>),\n",
      " tensor([[[ 3.1816e-02, -7.3114e-01,  9.4831e+00,  1.8992e+01],\n",
      "         [ 1.0725e+00, -3.5477e-01,  2.0504e+01,  2.4830e+01],\n",
      "         [ 4.0712e+00, -6.4097e-01,  2.8656e+01,  2.0241e+01],\n",
      "         ...,\n",
      "         [ 8.2616e+02,  3.2527e+02,  1.0436e+03,  6.4307e+02],\n",
      "         [ 8.6107e+02,  3.2394e+02,  1.0574e+03,  6.4645e+02],\n",
      "         [ 9.0088e+02,  3.1932e+02,  1.0688e+03,  6.5103e+02]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "\n",
      "tensor([[20]], device='cuda:0') tensor([[[ 8.9127e+02, -5.8867e-01,  9.2423e+02,  1.1185e+01],\n",
      "         [ 8.8632e+02, -5.4145e-01,  9.1406e+02,  1.0748e+01],\n",
      "         [ 8.6733e+02, -6.7029e-01,  8.9873e+02,  1.1218e+01],\n",
      "         [ 8.6054e+02, -6.3371e-01,  8.9190e+02,  1.1249e+01],\n",
      "         [ 8.4895e+02, -6.1919e-01,  8.8412e+02,  1.0891e+01],\n",
      "         [ 8.7806e+02, -5.2865e-01,  9.0463e+02,  1.1201e+01],\n",
      "         [ 9.0054e+02, -6.2620e-01,  9.3347e+02,  1.1827e+01],\n",
      "         [ 9.1023e+02, -6.4887e-01,  9.4285e+02,  1.2821e+01],\n",
      "         [ 9.1721e+02, -7.8171e-01,  9.5417e+02,  1.2091e+01],\n",
      "         [ 8.4034e+02, -6.5869e-01,  8.7513e+02,  1.0085e+01],\n",
      "         [ 9.2497e+02, -8.1836e-01,  9.5711e+02,  1.2114e+01],\n",
      "         [ 8.3785e+02, -5.6003e-01,  8.6563e+02,  9.3339e+00],\n",
      "         [ 9.3161e+02, -8.4197e-01,  9.6612e+02,  1.1931e+01],\n",
      "         [ 8.3092e+02, -4.2893e-01,  8.6176e+02,  9.6749e+00],\n",
      "         [ 9.4075e+02, -7.6127e-01,  9.6996e+02,  1.1230e+01],\n",
      "         [ 7.7614e+02, -6.9484e-01,  8.3001e+02,  9.9164e+00],\n",
      "         [ 7.8964e+02, -5.9031e-01,  8.3499e+02,  1.0238e+01],\n",
      "         [ 8.2145e+02, -4.4771e-01,  8.5651e+02,  1.0425e+01],\n",
      "         [ 8.0736e+02, -5.6075e-01,  8.5147e+02,  1.0712e+01],\n",
      "         [ 7.9878e+02, -6.0884e-01,  8.4339e+02,  1.0642e+01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>) tensor([[1.4117e-06, 1.3665e-06, 1.3501e-06, 1.3211e-06, 1.2267e-06, 1.2222e-06,\n",
      "         1.1549e-06, 1.1073e-06, 1.0438e-06, 1.0001e-06, 9.1889e-07, 8.7547e-07,\n",
      "         7.5934e-07, 6.6358e-07, 6.2192e-07, 6.0125e-07, 5.7948e-07, 5.5787e-07,\n",
      "         5.4723e-07, 5.2145e-07, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>) tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0., -1.]], device='cuda:0',\n",
      "       dtype=torch.float16)\n",
      "tensor([[[2.6420e-06, 3.4048e-06, 5.1786e-07,  ..., 1.1198e-07,\n",
      "          1.5851e-07, 3.1042e-07],\n",
      "         [1.4929e-06, 1.8949e-06, 4.7566e-07,  ..., 7.3506e-08,\n",
      "          1.0516e-07, 2.8325e-07],\n",
      "         [1.7293e-06, 2.0379e-06, 5.7483e-07,  ..., 1.0807e-07,\n",
      "          1.2615e-07, 4.2165e-07],\n",
      "         ...,\n",
      "         [1.0137e-05, 2.1717e-06, 2.1370e-06,  ..., 7.6352e-07,\n",
      "          7.0239e-07, 6.3568e-07],\n",
      "         [1.1687e-05, 2.6276e-06, 2.1325e-06,  ..., 7.6168e-07,\n",
      "          7.0075e-07, 6.3523e-07],\n",
      "         [3.1379e-06, 1.5073e-06, 1.7049e-06,  ..., 6.8885e-07,\n",
      "          6.3803e-07, 5.8625e-07]]], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward0>),\n",
      " tensor([[[ 3.1816e-02, -7.3114e-01,  9.4831e+00,  1.8992e+01],\n",
      "         [ 1.0725e+00, -3.5477e-01,  2.0504e+01,  2.4830e+01],\n",
      "         [ 4.0712e+00, -6.4097e-01,  2.8656e+01,  2.0241e+01],\n",
      "         ...,\n",
      "         [ 8.2616e+02,  3.2527e+02,  1.0436e+03,  6.4307e+02],\n",
      "         [ 8.6107e+02,  3.2394e+02,  1.0574e+03,  6.4645e+02],\n",
      "         [ 9.0088e+02,  3.1932e+02,  1.0688e+03,  6.5103e+02]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "\n",
      "tensor([[20]], device='cuda:0') tensor([[[ 8.9127e+02, -5.8867e-01,  9.2423e+02,  1.1185e+01],\n",
      "         [ 8.8632e+02, -5.4145e-01,  9.1406e+02,  1.0748e+01],\n",
      "         [ 8.6733e+02, -6.7029e-01,  8.9873e+02,  1.1218e+01],\n",
      "         [ 8.6054e+02, -6.3371e-01,  8.9190e+02,  1.1249e+01],\n",
      "         [ 8.4895e+02, -6.1919e-01,  8.8412e+02,  1.0891e+01],\n",
      "         [ 8.7806e+02, -5.2865e-01,  9.0463e+02,  1.1201e+01],\n",
      "         [ 9.0054e+02, -6.2620e-01,  9.3347e+02,  1.1827e+01],\n",
      "         [ 9.1023e+02, -6.4887e-01,  9.4285e+02,  1.2821e+01],\n",
      "         [ 9.1721e+02, -7.8171e-01,  9.5417e+02,  1.2091e+01],\n",
      "         [ 8.4034e+02, -6.5869e-01,  8.7513e+02,  1.0085e+01],\n",
      "         [ 9.2497e+02, -8.1836e-01,  9.5711e+02,  1.2114e+01],\n",
      "         [ 8.3785e+02, -5.6003e-01,  8.6563e+02,  9.3339e+00],\n",
      "         [ 9.3161e+02, -8.4197e-01,  9.6612e+02,  1.1931e+01],\n",
      "         [ 8.3092e+02, -4.2893e-01,  8.6176e+02,  9.6749e+00],\n",
      "         [ 9.4075e+02, -7.6127e-01,  9.6996e+02,  1.1230e+01],\n",
      "         [ 7.7614e+02, -6.9484e-01,  8.3001e+02,  9.9164e+00],\n",
      "         [ 7.8964e+02, -5.9031e-01,  8.3499e+02,  1.0238e+01],\n",
      "         [ 8.2145e+02, -4.4771e-01,  8.5651e+02,  1.0425e+01],\n",
      "         [ 8.0736e+02, -5.6075e-01,  8.5147e+02,  1.0712e+01],\n",
      "         [ 7.9878e+02, -6.0884e-01,  8.4339e+02,  1.0642e+01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>) tensor([[1.4117e-06, 1.3665e-06, 1.3501e-06, 1.3211e-06, 1.2267e-06, 1.2222e-06,\n",
      "         1.1549e-06, 1.1073e-06, 1.0438e-06, 1.0001e-06, 9.1889e-07, 8.7547e-07,\n",
      "         7.5934e-07, 6.6358e-07, 6.2192e-07, 6.0125e-07, 5.7948e-07, 5.5787e-07,\n",
      "         5.4723e-07, 5.2145e-07, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>) tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0., -1.]], device='cuda:0',\n",
      "       dtype=torch.float16)\n",
      "ONNX export success, save into work_dirs/yolov8_l_planitar/best_coco_bbox_mAP_epoch_200.onnx\n"
     ]
    }
   ],
   "source": [
    "!python projects/easydeploy/tools/export_onnx.py \\\n",
    "    configs/yolov8/yolov8_l_planitar.py \\\n",
    "    work_dirs/yolov8_l_planitar/best_coco_bbox_mAP_epoch_200.pth \\\n",
    "    --work-dir work_dirs/yolov8_l_planitar/ \\\n",
    "    --img-size 512 1024 \\\n",
    "    --batch 1 \\\n",
    "    --device cuda \\\n",
    "    --simplify \\\n",
    "    --opset 11 \\\n",
    "    --backend \"onnxruntime\" \\\n",
    "    --pre-topk 1000 \\\n",
    "    --keep-topk 100 \\\n",
    "    --iou-threshold 0.6 \\\n",
    "    --score-threshold 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3d90868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: work_dirs/yolov8_s_fast_1xb12_100e_planitar_premium/best_coco_bbox_mAP_epoch_40.pth\n",
      "ONNX export success, save into work_dirs/yolov8_s_fast_1xb12_100e_planitar_premium/best_coco_bbox_mAP_epoch_40.onnx\n"
     ]
    }
   ],
   "source": [
    "!python projects/easydeploy/tools/export_onnx.py \\\n",
    "    configs/yolov8/yolov8_s_fast_1xb12_100e_planitar_premium.py \\\n",
    "    work_dirs/yolov8_s_fast_1xb12_100e_planitar_premium/best_coco_bbox_mAP_epoch_40.pth \\\n",
    "    --work-dir work_dirs/yolov8_s_fast_1xb12_100e_planitar_premium/ \\\n",
    "    --img-size 512 1024 \\\n",
    "    --batch 1 \\\n",
    "    --device cpu \\\n",
    "    --simplify \\\n",
    "    --opset 11 \\\n",
    "    --backend \"onnxruntime\" \\\n",
    "    --pre-topk 1000 \\\n",
    "    --keep-topk 100 \\\n",
    "    --iou-threshold 0.65 \\\n",
    "    --score-threshold 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a83c611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mmdeploy.apis import torch2onnx\n",
    "# from mmdeploy.backend.sdk.export_info import export2SDK\n",
    "\n",
    "# img = '/home/bizon/planitar_github/draft-automation/object_detection/yolov7/runs/images/ig00NF5P5F96QD1_1.jpg'\n",
    "# work_dir = 'work_dirs/yolov8_l_syncbn_fast_8xb16-500e_coco'\n",
    "# save_file = 'end2end.onnx'\n",
    "# deploy_cfg = 'configs/deploy/detection_onnxruntime_static.py'\n",
    "# model_cfg = 'configs/yolov8/yolov8_l_syncbn_fast_8xb16-500e_coco.py'\n",
    "# model_checkpoint = 'work_dirs/yolov8_l_syncbn_fast_8xb16-500e_coco/best_coco_bbox_mAP_epoch_98.pth'\n",
    "# device = 'cpu'\n",
    "\n",
    "# # 1. convert model to onnx\n",
    "# torch2onnx(img, work_dir, save_file, deploy_cfg, model_cfg,\n",
    "#            model_checkpoint, device)\n",
    "\n",
    "# # 2. extract pipeline info for inference by MMDeploy SDK\n",
    "# export2SDK(deploy_cfg, model_cfg, work_dir, pth=model_checkpoint,\n",
    "#            device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29a2422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mmdeploy_runtime import Detector\n",
    "# import cv2\n",
    "\n",
    "# img = cv2.imread('/home/bizon/planitar_github/draft-automation/object_detection/yolov7/runs/images/ig00NF5P5F96QD1_1.jpg')\n",
    "\n",
    "# # create a detector\n",
    "# detector = Detector(model_path='/home/bizon/projects/experiments/mmdetection_yolo/mmyolo_test/yolov8_l_v18.onnx',\n",
    "#                     device_name='cpu', device_id=0)\n",
    "# # perform inference\n",
    "# bboxes, labels, masks = detector(img)\n",
    "\n",
    "# # visualize inference result\n",
    "# indices = [i for i in range(len(bboxes))]\n",
    "# for index, bbox, label_id in zip(indices, bboxes, labels):\n",
    "#     [left, top, right, bottom], score = bbox[0:4].astype(int), bbox[4]\n",
    "#     if score < 0.3:\n",
    "#         continue\n",
    "\n",
    "#     cv2.rectangle(img, (left, top), (right, bottom), (0, 255, 0))\n",
    "\n",
    "# cv2.imwrite('work_dir/output_detection.png', img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
